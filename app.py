# -*- coding: utf-8 -*-
"""app.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/113oRLaFNWD6QtQ6eGrxIhEFkmlvueZT9
"""

import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import plotly.graph_objects as go

# ----------------------------
# Page setup
# ----------------------------
st.set_page_config(page_title="Approval Insights Dashboard", layout="wide")
st.title("Approval Insights Dashboard")
st.caption(
    "Interactive dashboard for approval behavior, fast approvals, block analysis, and hypothesis tests. "
    "Includes filters, KPI trends, benchmark lines, heatmaps, suspicious ranking, and downloads."
)

# ----------------------------
# Helpers
# ----------------------------
@st.cache_data
def load_excel(uploaded_file):
    xls = pd.ExcelFile(uploaded_file)
    return {name: pd.read_excel(xls, name) for name in xls.sheet_names}

def ensure_datetime(df, col):
    if df is not None and col in df.columns:
        df[col] = pd.to_datetime(df[col], errors="coerce")
    return df

def safe_col(df, candidates):
    if df is None:
        return None
    for c in candidates:
        if c in df.columns:
            return c
    return None

def to_num(s):
    return pd.to_numeric(s, errors="coerce")

def add_duration_benchmarks(fig, axis="x", unit="sec"):
    """
    Adds reference lines at 10, 5, 2 minutes.
    If duration is on x-axis (histogram) -> axis="x" (vertical lines)
    If duration is on y-axis (bar) -> axis="y" (horizontal lines)
    """
    if unit == "sec":
        points = [(600, "10 min"), (300, "5 min"), (120, "2 min")]
    else:
        points = [(10, "10 min"), (5, "5 min"), (2, "2 min")]

    for v, label in points:
        if axis == "x":
            fig.add_vline(x=v, line_dash="dash", annotation_text=label, annotation_position="top")
        else:
            fig.add_hline(y=v, line_dash="dash", annotation_text=label, annotation_position="top left")
    return fig

def download_button_df(df: pd.DataFrame, label: str, filename: str, key: str):
    csv = df.to_csv(index=False).encode("utf-8")
    st.download_button(label=label, data=csv, file_name=filename, mime="text/csv", key=key)

# ----------------------------
# Upload
# ----------------------------
uploaded = st.file_uploader("Upload approval_analysis_output.xlsx", type=["xlsx"])
if not uploaded:
    st.info("ğŸ‘† Upload `approval_analysis_output.xlsx` to load the dashboard.")
    st.stop()

sheets = load_excel(uploaded)
st.success(f"Loaded sheets: {', '.join(sheets.keys())}")

# Core sheets (based on your file)
clean = sheets.get("clean_data")
tech = sheets.get("technician_summary")
fast_thr = sheets.get("fast_thresholds")
block_kpis = sheets.get("block_kpis")
one_sample = sheets.get("one_sample_ttests")
payout = sheets.get("payout_two_sample")
within_tech = sheets.get("within_block_tech_summary")
within_dist = sheets.get("within_block_distributions")
block_first_rest = sheets.get("block_first_vs_rest_summary")
block_tests = sheets.get("block_first_vs_rest_tests")
sus_blocks = sheets.get("suspicious_blocks")

# New optional sheet name(s) user mentioned
sus_rank = (
    sheets.get("Suspicious Ranking")
    or sheets.get("suspicious_ranking")
    or sheets.get("suspicious_ranking ")
)

# Clean data required
if clean is None:
    st.error("Sheet `clean_data` not found. Your Excel must include a `clean_data` tab.")
    st.stop()

# Ensure datetimes
clean = ensure_datetime(clean, "approval_dt")
clean = ensure_datetime(clean, "prev_approval_dt")

# Identify key columns in clean_data
tech_col = safe_col(clean, ["technician", "Technician", "provider_approving_name"])
dt_col = safe_col(clean, ["approval_dt", "Approval_DT", "approval_date"])
weekday_col = safe_col(clean, ["weekday", "Weekday"])
hour_col = safe_col(clean, ["hour", "Hour"])
duration_sec_col = safe_col(clean, ["duration_sec", "duration_seconds", "Duration_Sec"])

if tech_col is None or dt_col is None:
    st.error("`clean_data` must contain `technician` and `approval_dt` columns.")
    st.stop()

df = clean.copy()

# ----------------------------
# Sidebar Filters
# ----------------------------
st.sidebar.header("Filters")

dt_series = pd.to_datetime(df[dt_col], errors="coerce")
min_date = pd.to_datetime(dt_series.min()).date()
max_date = pd.to_datetime(dt_series.max()).date()

date_range = st.sidebar.date_input(
    "Date range",
    value=(min_date, max_date),
    min_value=min_date,
    max_value=max_date
)

if isinstance(date_range, tuple) and len(date_range) == 2:
    start_date, end_date = date_range
else:
    start_date, end_date = min_date, max_date

all_techs = sorted(df[tech_col].dropna().astype(str).unique())
selected_techs = st.sidebar.multiselect("Technician(s)", all_techs, default=all_techs)

if weekday_col:
    weekdays = sorted([w for w in df[weekday_col].dropna().unique()])
    selected_weekdays = st.sidebar.multiselect("Weekday(s)", weekdays, default=weekdays)
else:
    selected_weekdays = None

if hour_col:
    h = to_num(df[hour_col])
    min_h = int(np.nanmin(h))
    max_h = int(np.nanmax(h))
    hour_range = st.sidebar.slider("Hour range", min_h, max_h, (min_h, max_h))
else:
    hour_range = None

# Apply filters to clean_data
mask = (
    df[tech_col].astype(str).isin([str(x) for x in selected_techs]) &
    (pd.to_datetime(df[dt_col]).dt.date >= start_date) &
    (pd.to_datetime(df[dt_col]).dt.date <= end_date)
)

if weekday_col and selected_weekdays is not None:
    mask &= df[weekday_col].isin(selected_weekdays)

if hour_col and hour_range is not None:
    hh = to_num(df[hour_col])
    mask &= (hh >= hour_range[0]) & (hh <= hour_range[1])

fdf = df.loc[mask].copy()

# ----------------------------
# KPI Row + Trend Deltas (previous equal-length period)
# ----------------------------
total_days = (pd.to_datetime(end_date) - pd.to_datetime(start_date)).days + 1
prev_end = pd.to_datetime(start_date) - pd.Timedelta(days=1)
prev_start = prev_end - pd.Timedelta(days=total_days - 1)

pmask = (
    df[tech_col].astype(str).isin([str(x) for x in selected_techs]) &
    (pd.to_datetime(df[dt_col]).dt.date >= prev_start.date()) &
    (pd.to_datetime(df[dt_col]).dt.date <= prev_end.date())
)
if weekday_col and selected_weekdays is not None:
    pmask &= df[weekday_col].isin(selected_weekdays)
if hour_col and hour_range is not None:
    hh = to_num(df[hour_col])
    pmask &= (hh >= hour_range[0]) & (hh <= hour_range[1])

pdf = df.loc[pmask].copy()

def kpi_stats(dd):
    out = {}
    out["approvals"] = len(dd)
    out["techs"] = dd[tech_col].nunique()
    if duration_sec_col:
        dur = to_num(dd[duration_sec_col])
        out["median_sec"] = float(np.nanmedian(dur))
        out["mean_sec"] = float(np.nanmean(dur))
        out["fast_lt_5_pct"] = float(np.nanmean(dur < 5) * 100)
    else:
        out["median_sec"] = np.nan
        out["mean_sec"] = np.nan
        out["fast_lt_5_pct"] = np.nan
    return out

cur = kpi_stats(fdf)
prev = kpi_stats(pdf)

def safe_delta(cur_v, prev_v):
    # hide delta if previous is empty/invalid to avoid misleading big arrows
    if prev_v in [0, None] or (isinstance(prev_v, float) and np.isnan(prev_v)):
        return None
    return cur_v - prev_v

k1, k2, k3, k4, k5 = st.columns(5)
k1.metric("Total approvals", f"{cur['approvals']:,}", delta=safe_delta(cur["approvals"], prev["approvals"]))
k2.metric("Technicians", f"{cur['techs']:,}", delta=safe_delta(cur["techs"], prev["techs"]))
k3.metric("Median duration (sec)", f"{cur['median_sec']:.2f}" if np.isfinite(cur["median_sec"]) else "NA",
          delta=(cur["median_sec"] - prev["median_sec"]) if np.isfinite(cur["median_sec"]) and np.isfinite(prev["median_sec"]) else None)
k4.metric("Mean duration (sec)", f"{cur['mean_sec']:.2f}" if np.isfinite(cur["mean_sec"]) else "NA",
          delta=(cur["mean_sec"] - prev["mean_sec"]) if np.isfinite(cur["mean_sec"]) and np.isfinite(prev["mean_sec"]) else None)
k5.metric("Fast < 5 sec (%)", f"{cur['fast_lt_5_pct']:.1f}%" if np.isfinite(cur["fast_lt_5_pct"]) else "NA",
          delta=(cur["fast_lt_5_pct"] - prev["fast_lt_5_pct"]) if np.isfinite(cur["fast_lt_5_pct"]) and np.isfinite(prev["fast_lt_5_pct"]) else None)

st.divider()

# ============================================================
#  âœ… REPLACEMENT SECTION: Suspicious Ranking (instead of Risk Scoring)
# ============================================================
st.subheader("Suspicious Ranking")

# show formula nicely + explanation
with st.expander("How Suspicion Score is computed"):
    st.markdown(
        r"""
**Suspicion Score** combines speed, clustering, and consistency signals:

\[
\textbf{Suspicion Score} =
\text{Pct}_{<10s}
\;+\;
2 \times \text{Approvals in Block}
\;+\;
\Bigl(10 - \min(\text{Median Duration (sec)}, 10)\Bigr)
\]

**Interpretation (higher score = more suspicious):**
- **Pct < 10s** increases the score when approvals are unusually fast
- **2 Ã— Approvals in Block** increases the score when approvals are heavily clustered
- **(10 âˆ’ min(median,10))** increases the score when typical duration is very short (capped at 10 sec)
"""
    )

st.caption("Below ranking is based on the block-level suspicious behavior (highest suspicion score first).")

# Build / load Suspicious Ranking table
# If user added a dedicated sheet, use it. Otherwise build from suspicious_blocks.
ranking_source = None

if sus_rank is not None:
    ranking_source = sus_rank.copy()
else:
    if sus_blocks is not None:
        ranking_source = sus_blocks.copy()
    else:
        ranking_source = None

if ranking_source is None:
    st.info("No suspicious ranking data found. Add `suspicious_blocks` or `Suspicious Ranking` sheet to the Excel file.")
else:
    # Make sure required columns exist (expected from suspicious_blocks)
    # technician, block_id, approvals_in_block, median_duration_sec, pct_lt_10s, suspicion_score
    tcol = safe_col(ranking_source, ["technician", "Technician"])
    score_col = safe_col(ranking_source, ["suspicion_score", "Suspicion Score", "suspicionScore"])
    pct10_col = safe_col(ranking_source, ["pct_lt_10s", "Pct < 10s", "pct_under_10s"])
    appr_col = safe_col(ranking_source, ["approvals_in_block", "Approvals in Block"])
    med_col = safe_col(ranking_source, ["median_duration_sec", "Median Duration (sec)", "median_sec"])
    block_col = safe_col(ranking_source, ["block_id", "Block ID", "block"])

    if score_col is None and (pct10_col and appr_col and med_col):
        # compute if not present
        # suspicion_score = pct_lt_10s + 2*approvals_in_block + (10 - min(median_duration_sec,10))
        med = to_num(ranking_source[med_col])
        ranking_source["suspicion_score"] = (
            to_num(ranking_source[pct10_col]) +
            2 * to_num(ranking_source[appr_col]) +
            (10 - np.minimum(med, 10))
        )
        score_col = "suspicion_score"

    if score_col is None:
        st.error("Cannot compute or find `suspicion_score`. Ensure columns exist: pct_lt_10s, approvals_in_block, median_duration_sec.")
    else:
        # Sort by score desc
        ranking_source[score_col] = to_num(ranking_source[score_col])
        ranking_source = ranking_source.sort_values(score_col, ascending=False)

        # Choose view: by block or by technician
        view = st.radio("View ranking by:", ["Blocks", "Technicians"], horizontal=True)

        if view == "Blocks":
            n = min(20, len(ranking_source))
            st.write(f"Showing top **{n}** blocks by Suspicion Score (filtered selection).")

            # Table
            show_cols = [c for c in [tcol, block_col, appr_col, med_col, pct10_col, score_col] if c and c in ranking_source.columns]
            st.dataframe(ranking_source[show_cols].head(n), use_container_width=True)

            # Graph
            # Use label = "technician - block_id" if both exist
            plot_df = ranking_source.head(n).copy()
            if tcol and block_col and tcol in plot_df.columns and block_col in plot_df.columns:
                plot_df["label"] = plot_df[tcol].astype(str) + " | Block " + plot_df[block_col].astype(str)
                xcol = "label"
            else:
                xcol = tcol if tcol else (block_col if block_col else None)

            if xcol:
                fig = px.bar(plot_df, x=xcol, y=score_col, title=f"Top {n} Blocks by Suspicion Score")
                fig.update_layout(xaxis_title="", yaxis_title="Suspicion Score")
                st.plotly_chart(fig, use_container_width=True)

            download_button_df(ranking_source[show_cols], "Download Suspicious Ranking (Blocks) (CSV)", "suspicious_ranking_blocks.csv", "dl_susp_blocks")

        else:
            if tcol is None or tcol not in ranking_source.columns:
                st.info("Cannot build technician ranking because technician column not found.")
            else:
                # Aggregate per technician
                agg = ranking_source.groupby(tcol).agg(
                    blocks=("suspicion_score", "size"),
                    max_suspicion=(score_col, "max"),
                    avg_suspicion=(score_col, "mean")
                ).reset_index().sort_values("max_suspicion", ascending=False)

                n = min(20, len(agg))
                st.write(f"Showing top **{n}** technicians by **Max Suspicion Score** (filtered selection).")

                st.dataframe(agg.head(n), use_container_width=True)

                fig = px.bar(agg.head(n), x=tcol, y="max_suspicion", title=f"Top {n} Technicians by Max Suspicion Score")
                fig.update_layout(xaxis_title="Technician", yaxis_title="Max Suspicion Score")
                st.plotly_chart(fig, use_container_width=True)

                download_button_df(agg, "Download Suspicious Ranking (Technicians) (CSV)", "suspicious_ranking_technicians.csv", "dl_susp_tech")

st.divider()

# ----------------------------
# Tabs
# ----------------------------
tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
    "Overview",
    "Technician Deep Dive",
    "Heatmap",
    "Block Analysis",
    "Hypothesis Tests",
    "Suspicious Blocks"
])

# ----------------------------
# TAB 1: Overview
# ----------------------------
with tab1:
    left, right = st.columns([1.2, 1])

    with left:
        st.subheader("Approvals over time")
        tmp = fdf.copy()
        tmp["date"] = pd.to_datetime(tmp[dt_col]).dt.date
        daily = tmp.groupby("date").size().reset_index(name="approvals")
        fig = px.line(daily, x="date", y="approvals", markers=True)
        st.plotly_chart(fig, use_container_width=True)

    with right:
        st.subheader("Duration distribution")
        if duration_sec_col:
            tmp = fdf.copy()
            tmp["_dur"] = to_num(tmp[duration_sec_col])
            tmp = tmp.dropna(subset=["_dur"])
            fig = px.histogram(tmp, x="_dur", nbins=60)
            fig = add_duration_benchmarks(fig, axis="x", unit="sec")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Duration column not found in clean_data.")

    st.subheader("Approvals by technician")
    top = fdf.groupby(tech_col).size().reset_index(name="approvals").sort_values("approvals", ascending=False)
    fig = px.bar(top, x=tech_col, y="approvals")
    st.plotly_chart(fig, use_container_width=True)

    download_button_df(fdf, "Download Filtered clean_data (CSV)", "clean_data_filtered.csv", "dl_clean_filtered")

# ----------------------------
# TAB 2: Technician Deep Dive
# ----------------------------
with tab2:
    st.subheader("Technician summary")
    if tech is not None:
        st.dataframe(tech, use_container_width=True)

        tcol = safe_col(tech, ["technician", "Technician"])
        approvals_col = safe_col(tech, ["n_approvals", "approvals", "count"])
        med_col = safe_col(tech, ["median_duration_sec", "median_sec", "median_duration"])
        fast5_col = safe_col(tech, ["pct_fast_lt_5s", "fast_lt_5s_pct", "pct_fast_5s"])

        # Dynamic N (no "top 25" wording)
        n_tech = len(tech) if tech is not None else 0
        top_n = min(25, n_tech) if n_tech else 0

        c1, c2 = st.columns(2)

        with c1:
            if tcol and approvals_col:
                fig = px.bar(
                    tech.sort_values(approvals_col, ascending=False).head(top_n),
                    x=tcol, y=approvals_col,
                    title="Approvals by technician"
                )
                st.plotly_chart(fig, use_container_width=True)

        with c2:
            if tcol and med_col:
                fig = px.bar(
                    tech.sort_values(med_col, ascending=False).head(top_n),
                    x=tcol, y=med_col,
                    title="Median duration (sec) by technician"
                )
                fig = add_duration_benchmarks(fig, axis="y", unit="sec")
                st.plotly_chart(fig, use_container_width=True)

        if tcol and fast5_col:
            fig = px.bar(
                tech.sort_values(fast5_col, ascending=False).head(top_n),
                x=tcol, y=fast5_col,
                title="Fast < 5 sec (%) by technician"
            )
            st.plotly_chart(fig, use_container_width=True)

    else:
        st.info("Sheet `technician_summary` not found.")

    st.subheader("Filtered approvals (preview)")
    st.dataframe(fdf.head(500), use_container_width=True)

# ----------------------------
# TAB 3: Heatmap (Weekday x Hour)
# ----------------------------
with tab3:
    st.subheader("Heatmap: Weekday Ã— Hour (Median duration in seconds)")
    if weekday_col and hour_col and duration_sec_col:
        tmp = fdf.copy()
        tmp["_hour"] = to_num(tmp[hour_col]).astype("Int64")
        tmp["_dur"] = to_num(tmp[duration_sec_col])
        tmp = tmp.dropna(subset=["_hour", "_dur", weekday_col])

        pivot = tmp.pivot_table(
            index=weekday_col,
            columns="_hour",
            values="_dur",
            aggfunc="median"
        )

        fig = go.Figure(
            data=go.Heatmap(
                z=pivot.values,
                x=[int(x) for x in pivot.columns],
                y=pivot.index.astype(str).tolist(),
                colorbar=dict(title="Median sec")
            )
        )
        fig.update_layout(xaxis_title="Hour of day", yaxis_title="Weekday", height=450)
        st.plotly_chart(fig, use_container_width=True)
        st.caption("Use filters to focus on technicians, dates, weekdays, or hours.")
    else:
        st.info("Heatmap needs `weekday`, `hour`, and `duration_sec` columns in `clean_data`.")

# ----------------------------
# TAB 4: Block Analysis
# ----------------------------
with tab4:
    st.subheader("Block KPIs")
    if block_kpis is not None:
        st.dataframe(block_kpis, use_container_width=True)
        download_button_df(block_kpis, "Download Block KPIs (CSV)", "block_kpis.csv", "dl_block_kpis")
    else:
        st.info("Sheet `block_kpis` not found.")

    st.subheader("Within-block distributions")
    if within_dist is not None:
        st.dataframe(within_dist, use_container_width=True)
        download_button_df(within_dist, "Download Within-block Distributions (CSV)", "within_block_distributions.csv", "dl_within_dist")
    else:
        st.info("Sheet `within_block_distributions` not found.")

    st.subheader("Within-block technician summary")
    if within_tech is not None:
        st.dataframe(within_tech, use_container_width=True)
        download_button_df(within_tech, "Download Within-block Technician Summary (CSV)", "within_block_tech_summary.csv", "dl_within_tech")
    else:
        st.info("Sheet `within_block_tech_summary` not found.")

    st.subheader("First approval vs Rest of block")
    if block_first_rest is not None:
        st.dataframe(block_first_rest, use_container_width=True)

        btech = safe_col(block_first_rest, ["technician", "Technician"])
        first_col = safe_col(block_first_rest, ["first_mean_sec", "first_avg_sec", "first_mean", "first_duration_mean_sec", "first_median_sec"])
        rest_col  = safe_col(block_first_rest, ["rest_mean_sec", "rest_avg_sec", "rest_mean", "rest_duration_mean_sec", "rest_median_sec"])

        if btech and first_col and rest_col:
            plot_df = block_first_rest[[btech, first_col, rest_col]].dropna()
            top_n = min(25, len(plot_df))
            plot_df = plot_df.head(top_n)

            melted = plot_df.melt(
                id_vars=[btech],
                value_vars=[first_col, rest_col],
                var_name="block_part",
                value_name="duration_sec"
            )
            fig = px.bar(melted, x=btech, y="duration_sec", color="block_part", barmode="group",
                         title="First approval vs Rest of block (duration in seconds)")
            fig = add_duration_benchmarks(fig, axis="y", unit="sec")
            st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("Could not auto-detect first/rest duration columns in block_first_vs_rest_summary.")

        download_button_df(block_first_rest, "Download First vs Rest Summary (CSV)", "block_first_vs_rest_summary.csv", "dl_first_rest")
    else:
        st.info("Sheet `block_first_vs_rest_summary` not found.")

# ----------------------------
# TAB 5: Hypothesis Tests
# ----------------------------
with tab5:
    st.subheader("One-sample t-tests vs benchmarks")
    if one_sample is not None:
        st.dataframe(one_sample, use_container_width=True)
        download_button_df(one_sample, "Download One-sample T-tests (CSV)", "one_sample_ttests.csv", "dl_one_sample")
    else:
        st.info("Sheet `one_sample_ttests` not found.")

    st.subheader("Payout two-sample test")
    if payout is not None:
        st.dataframe(payout, use_container_width=True)
        download_button_df(payout, "Download Payout Two-sample Results (CSV)", "payout_two_sample.csv", "dl_payout")
    else:
        st.info("Sheet `payout_two_sample` not found.")

    st.subheader("Block first vs rest tests")
    if block_tests is not None:
        st.dataframe(block_tests, use_container_width=True)
        download_button_df(block_tests, "Download Block First vs Rest Tests (CSV)", "block_first_vs_rest_tests.csv", "dl_block_tests")
    else:
        st.info("Sheet `block_first_vs_rest_tests` not found.")

# ----------------------------
# TAB 6: Suspicious Blocks
# ----------------------------
with tab6:
    st.subheader("Suspicious blocks")
    if sus_blocks is not None:
        st.dataframe(sus_blocks, use_container_width=True)
        download_button_df(sus_blocks, "Download Suspicious Blocks (CSV)", "suspicious_blocks.csv", "dl_sus")
    else:
        st.info("Sheet `suspicious_blocks` not found.")